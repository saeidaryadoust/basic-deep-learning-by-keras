{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Code Explanation:**\n",
        "\n",
        "1. **Import Libraries:**\n",
        "   - `keras`: For building and training the neural network.\n",
        "   - `matplotlib.pyplot`: For plotting graphs.\n",
        "   - `numpy`: For numerical operations.\n",
        "   - `keras.datasets.boston_housing`: To load the Boston Housing dataset.\n",
        "   - `sklearn.preprocessing.StandardScaler`: For scaling the data.\n",
        "\n",
        "2. **Load and Preprocess Data:**\n",
        "   - `(xtrain, ytrain), (xtest, ytest) = boston_housing.load_data()`: Loads the Boston Housing dataset, splitting it into training and testing sets.\n",
        "   - `print(ytrain.shape), print(ytest.shape), print(xtrain.shape)`: Prints the shapes of the loaded data.\n",
        "   - `sc = StandardScaler()`: Creates a StandardScaler object for data standardization.\n",
        "   - `xtrain = sc.fit_transform(xtrain)`: Fits the scaler to the training data and transforms it to have zero mean and unit variance.\n",
        "   - `xtest = sc.transform(xtest)`: Transforms the testing data using the same scaler fitted to the training data.\n",
        "\n",
        "3. **Build the Neural Network:**\n",
        "   - `model = keras.models.Sequential()`: Creates a sequential model, which is a linear stack of layers.\n",
        "   - `model.add(keras.layers.Dense(32, input_dim=13))`: Adds the first dense layer with 32 neurons and 13 input dimensions (matching the number of features in the dataset).\n",
        "   - `model.add(keras.layers.Activation('relu'))`: Adds a ReLU activation function to the first layer.\n",
        "   - `model.add(keras.layers.Dense(16))`: Adds a second dense layer with 16 neurons.\n",
        "   - `model.add(keras.layers.Activation('relu'))`: Adds a ReLU activation function to the second layer.\n",
        "   - `model.add(keras.layers.Dense(1))`: Adds the final dense layer with 1 neuron for the output (predicting the house price).\n",
        "\n",
        "4. **Model Summary:**\n",
        "   - `model.summary()`: Prints a summary of the model's architecture, including the number of layers, neurons, and parameters.\n",
        "\n",
        "5. **Compile the Model:**\n",
        "   - `model.compile(loss='mse', optimizer='adam', metrics=['mae'])`: Compiles the model with:\n",
        "     - `loss='mse'`: Mean squared error as the loss function.\n",
        "     - `optimizer='adam'`: Adam optimizer for updating weights.\n",
        "     - `metrics=['mae']`: Mean absolute error as a metric to evaluate performance.\n",
        "\n",
        "6. **Train the Model:**\n",
        "   - `history = model.fit(xtrain, ytrain, epochs=100, batch_size=32, validation_split=0.2)`: Trains the model for 100 epochs with a batch size of 32, using 20% of the training data for validation.\n",
        "\n",
        "7. **Evaluate the Model:**\n",
        "   - `loss, mae = model.evaluate(xtest, ytest, verbose=0)`: Evaluates the model on the testing data and prints the mean absolute error.\n",
        "\n",
        "8. **Plot Training and Validation Loss:**\n",
        "   - `plt.plot(history.history['loss'])`: Plots the training loss over epochs.\n",
        "   - `plt.plot(history.history['val_loss'])`: Plots the validation loss over epochs.\n",
        "   - The plot helps visualize the model's training progress and identify potential overfitting.\n",
        "\n",
        "9. **Make Predictions:**\n",
        "   - `predictions = model.predict(xtest)`: Makes predictions on the testing data using the trained model.\n",
        "\n",
        "10. **Plot Predictions vs Actual Values:**\n",
        "   - `plt.scatter(ytest, predictions)`: Creates a scatter plot comparing the actual house prices (ytest) to the predicted prices.\n",
        "   - This plot helps assess the model's accuracy visually.\n",
        "\n",
        "This code provides a basic example of using a Multi-Layer Perceptron (MLP) for regression on the Boston Housing dataset. You can further experiment with different network architectures, hyperparameters, and data preprocessing techniques to improve the model's performance."
      ],
      "metadata": {
        "id": "lPWdk15c8UEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import boston_housing\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "zhlvklYC8CJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(xtrain , ytrain , ), (xtest , ytest ) = boston_housing.load_data()"
      ],
      "metadata": {
        "id": "cZZEvdFUcne6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d313cea-a52c-470b-ec3f-3b101eb45c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytrain.shape)\n",
        "print(ytest.shape)\n",
        "print(xtrain.shape)"
      ],
      "metadata": {
        "id": "I0ngw57rc6wG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cdcdd4-9cdd-4a9f-d5ab-694a7e0f7894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404,)\n",
            "(102,)\n",
            "(404, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : for regression we dont need change data to categorical"
      ],
      "metadata": {
        "id": "FZdUqyXzYZmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "xtrain = sc.fit_transform(xtrain)\n",
        "print(xtrain.std())\n",
        "print(xtrain.mean())\n",
        "xtest = sc.transform(xtest)\n",
        "print(xtest.std())\n",
        "print(xtest.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg_ePQ9lY8GD",
        "outputId": "04dbcd72-0242-4afc-f115-01c1caf446ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9999999999999993\n",
            "2.6016254395785847e-15\n",
            "0.9836083446422431\n",
            "0.020826991430640224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# structure of network\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(32 , input_dim=13))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "model.add(keras.layers.Dense(16))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "model.add(keras.layers.Dense(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRwPD62wcKA6",
        "outputId": "9de65899-37a1-4ab7-c173-64a7987cec2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "0p7C4e04c942",
        "outputId": "ca666c1a-8a5c-41d6-c59e-92be7bed4377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m993\u001b[0m (3.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">993</span> (3.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m993\u001b[0m (3.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">993</span> (3.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(keras.optimizers.Adadelta(learning_rate=0.4),\n",
        "              loss='mse')"
      ],
      "metadata": {
        "id": "8VRMW_FadAb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_fit = model.fit(xtrain , ytrain , batch_size=128 , epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtMxmsFFdSna",
        "outputId": "ba87ae4c-3a1d-45ea-8253-c8251a0c4d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 592.3195\n",
            "Epoch 2/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 582.8068  \n",
            "Epoch 3/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 594.7973  \n",
            "Epoch 4/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 585.1133  \n",
            "Epoch 5/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 596.1165  \n",
            "Epoch 6/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 584.1524  \n",
            "Epoch 7/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 544.6520  \n",
            "Epoch 8/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 563.0872  \n",
            "Epoch 9/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 557.7675 \n",
            "Epoch 10/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 562.6957  \n",
            "Epoch 11/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 536.4077 \n",
            "Epoch 12/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 519.7214 \n",
            "Epoch 13/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 502.0865 \n",
            "Epoch 14/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 484.7754 \n",
            "Epoch 15/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 455.4774 \n",
            "Epoch 16/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 411.5962 \n",
            "Epoch 17/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 387.5334 \n",
            "Epoch 18/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 335.1186  \n",
            "Epoch 19/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 305.7674  \n",
            "Epoch 20/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 238.5955  \n",
            "Epoch 21/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 200.6431 \n",
            "Epoch 22/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165.8179 \n",
            "Epoch 23/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 144.2618  \n",
            "Epoch 24/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 116.0362 \n",
            "Epoch 25/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 103.0442  \n",
            "Epoch 26/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 92.1902   \n",
            "Epoch 27/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 81.9416  \n",
            "Epoch 28/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 71.8893 \n",
            "Epoch 29/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 55.6111 \n",
            "Epoch 30/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.7505 \n",
            "Epoch 31/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.3493  \n",
            "Epoch 32/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.6601 \n",
            "Epoch 33/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.1856 \n",
            "Epoch 34/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.8616 \n",
            "Epoch 35/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.1617  \n",
            "Epoch 36/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.2239  \n",
            "Epoch 37/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7836 \n",
            "Epoch 38/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7157  \n",
            "Epoch 39/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7632  \n",
            "Epoch 40/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 27.2040 \n",
            "Epoch 41/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7300  \n",
            "Epoch 42/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7136 \n",
            "Epoch 43/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.0328  \n",
            "Epoch 44/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.2585 \n",
            "Epoch 45/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24.6660 \n",
            "Epoch 46/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.0181 \n",
            "Epoch 47/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.4467 \n",
            "Epoch 48/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.7214  \n",
            "Epoch 49/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.9609  \n",
            "Epoch 50/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.8173 \n",
            "Epoch 51/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.6565  \n",
            "Epoch 52/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.1763  \n",
            "Epoch 53/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23.4530 \n",
            "Epoch 54/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.4343  \n",
            "Epoch 55/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.0058 \n",
            "Epoch 56/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.7808 \n",
            "Epoch 57/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.2318 \n",
            "Epoch 58/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.5580 \n",
            "Epoch 59/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.9530 \n",
            "Epoch 60/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.9092 \n",
            "Epoch 61/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.6998 \n",
            "Epoch 62/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.0852 \n",
            "Epoch 63/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.2235 \n",
            "Epoch 64/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.4254 \n",
            "Epoch 65/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.7197  \n",
            "Epoch 66/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.5406 \n",
            "Epoch 67/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.9540 \n",
            "Epoch 68/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.1817 \n",
            "Epoch 69/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.1717\n",
            "Epoch 70/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17.3485 \n",
            "Epoch 71/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19.9602 \n",
            "Epoch 72/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.0554  \n",
            "Epoch 73/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.9966 \n",
            "Epoch 74/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.1752  \n",
            "Epoch 75/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16.9149  \n",
            "Epoch 76/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6515 \n",
            "Epoch 77/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.0047 \n",
            "Epoch 78/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.0063 \n",
            "Epoch 79/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 15.1608 \n",
            "Epoch 80/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.2953  \n",
            "Epoch 81/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15.0891 \n",
            "Epoch 82/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 14.5045 \n",
            "Epoch 83/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 17.8863 \n",
            "Epoch 84/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.1837 \n",
            "Epoch 85/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.1341  \n",
            "Epoch 86/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.7647  \n",
            "Epoch 87/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.2997  \n",
            "Epoch 88/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.4024  \n",
            "Epoch 89/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.7837 \n",
            "Epoch 90/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.7104  \n",
            "Epoch 91/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.6606  \n",
            "Epoch 92/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.2755  \n",
            "Epoch 93/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.9056  \n",
            "Epoch 94/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 14.4952 \n",
            "Epoch 95/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.7466 \n",
            "Epoch 96/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.0022 \n",
            "Epoch 97/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.9917 \n",
            "Epoch 98/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.8454 \n",
            "Epoch 99/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.2325 \n",
            "Epoch 100/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.2887 \n",
            "Epoch 101/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.0439 \n",
            "Epoch 102/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.1653 \n",
            "Epoch 103/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.9383  \n",
            "Epoch 104/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.1142  \n",
            "Epoch 105/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.1457 \n",
            "Epoch 106/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.6101\n",
            "Epoch 107/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.1621 \n",
            "Epoch 108/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.2044 \n",
            "Epoch 109/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.5061 \n",
            "Epoch 110/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.9340  \n",
            "Epoch 111/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.0135  \n",
            "Epoch 112/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.8493  \n",
            "Epoch 113/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.6165 \n",
            "Epoch 114/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.1865 \n",
            "Epoch 115/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.4178 \n",
            "Epoch 116/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.9928 \n",
            "Epoch 117/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.4506  \n",
            "Epoch 118/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.9671\n",
            "Epoch 119/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.2413  \n",
            "Epoch 120/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.5629  \n",
            "Epoch 121/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.6833 \n",
            "Epoch 122/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.6548 \n",
            "Epoch 123/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.3405 \n",
            "Epoch 124/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.0789 \n",
            "Epoch 125/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4914 \n",
            "Epoch 126/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4140 \n",
            "Epoch 127/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.7274 \n",
            "Epoch 128/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.6261 \n",
            "Epoch 129/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7897  \n",
            "Epoch 130/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.8469  \n",
            "Epoch 131/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.9171  \n",
            "Epoch 132/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7596  \n",
            "Epoch 133/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.0897 \n",
            "Epoch 134/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.5458 \n",
            "Epoch 135/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.2382 \n",
            "Epoch 136/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.7064 \n",
            "Epoch 137/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7776  \n",
            "Epoch 138/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.5161 \n",
            "Epoch 139/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11.7194\n",
            "Epoch 140/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.5200\n",
            "Epoch 141/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3191\n",
            "Epoch 142/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.9934 \n",
            "Epoch 143/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0859\n",
            "Epoch 144/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5193\n",
            "Epoch 145/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.5918  \n",
            "Epoch 146/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.5273  \n",
            "Epoch 147/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.3129 \n",
            "Epoch 148/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.6645 \n",
            "Epoch 149/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.6513 \n",
            "Epoch 150/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.3633  \n",
            "Epoch 151/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.9762 \n",
            "Epoch 152/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5617\n",
            "Epoch 153/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.5106  \n",
            "Epoch 154/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.0545 \n",
            "Epoch 155/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.2123 \n",
            "Epoch 156/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.9481  \n",
            "Epoch 157/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.9313 \n",
            "Epoch 158/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.7159 \n",
            "Epoch 159/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.4190 \n",
            "Epoch 160/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5203  \n",
            "Epoch 161/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.1873 \n",
            "Epoch 162/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.1652 \n",
            "Epoch 163/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2606\n",
            "Epoch 164/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3110\n",
            "Epoch 165/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.1871\n",
            "Epoch 166/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 11.5015 \n",
            "Epoch 167/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.9292 \n",
            "Epoch 168/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.2349 \n",
            "Epoch 169/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.7422\n",
            "Epoch 170/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.9130  \n",
            "Epoch 171/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.8993 \n",
            "Epoch 172/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.8608 \n",
            "Epoch 173/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7735  \n",
            "Epoch 174/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2687 \n",
            "Epoch 175/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.6537  \n",
            "Epoch 176/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3188  \n",
            "Epoch 177/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.6472  \n",
            "Epoch 178/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.2860 \n",
            "Epoch 179/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.3635\n",
            "Epoch 180/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.3480 \n",
            "Epoch 181/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.8541 \n",
            "Epoch 182/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.6419\n",
            "Epoch 183/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.0310 \n",
            "Epoch 184/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.9696 \n",
            "Epoch 185/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.4005 \n",
            "Epoch 186/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7123 \n",
            "Epoch 187/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.0837 \n",
            "Epoch 188/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.5579 \n",
            "Epoch 189/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.4460\n",
            "Epoch 190/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.6994\n",
            "Epoch 191/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.8458\n",
            "Epoch 192/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.6713\n",
            "Epoch 193/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.3406 \n",
            "Epoch 194/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1859\n",
            "Epoch 195/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.6761 \n",
            "Epoch 196/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.3221\n",
            "Epoch 197/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9593 \n",
            "Epoch 198/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.9264 \n",
            "Epoch 199/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.1065 \n",
            "Epoch 200/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.6717 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_fit.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTNbB5aDdffB",
        "outputId": "3f92713f-0182-4883-f4b6-1fd09cf6dbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(output_fit.history['loss'])\n",
        "plt.xlabel('epoches')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "tRfTHaoXdnGr",
        "outputId": "9b3636d2-aabb-41b1-f2a1-69e98d4a16dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_prediction = model.predict(xtest , batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHOjBKj7d6BY",
        "outputId": "1905b1e3-db66-45c1-9d52-4c10c12ed244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(ytrain[0:10])\n",
        "# print(output_prediction)"
      ],
      "metadata": {
        "id": "by9hBb54eFxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_eval = model.evaluate(xtest , ytest , batch_size=64)\n",
        "print(out_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUFF2ZfKeIn4",
        "outputId": "b364d007-b90b-4d21-dacd-97cab99293f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16.3997  \n",
            "17.52066993713379\n"
          ]
        }
      ]
    }
  ]
}